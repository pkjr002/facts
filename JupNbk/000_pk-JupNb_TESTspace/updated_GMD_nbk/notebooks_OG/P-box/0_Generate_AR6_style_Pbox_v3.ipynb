{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24pt; color:blue; font-family: 'Times New Roman'\">P-box Notebook \n",
    "    <span style=\"color:green;\"> for creating AR6 style P-box data </span>\n",
    "</span>\n",
    "<br>\n",
    "<span style=\"font-size:12pt; color:black; font-family:Georgia, serif;font-style:italic\">by Praveen Kumar and Robert Kopp.</span>\n",
    "<br>\n",
    "<br>\n",
    "<span style=\"font-family: 'Times New Roman'; font-size:16pt; color:black\"> \n",
    "    This is a notebook that can be used to create and vizualize P-box data from raw <a href=\"https://doi.org/10.5194/egusphere-2023-14\" style=\"color:blue; text-decoration:underline;\">FACTS 1.0</a>\n",
    "    output. Workflows and associated *.nc files are created as part of this notebook. \n",
    "<br>\n",
    "<br>\n",
    "<span style=\"font-family:'Courier New', monospace; font-size:12pt; color:black\"> <b>Background::</b> <br>\n",
    "    In order to represent deep uncertainty, Probability boxes (p-boxes) can be constructed. These represent an envelope encompassing alternative probability distributions for describing the same variables. Within this notebook, we construct four p-boxes: <strong>1e, 1f, 2e,</strong> and <strong>2f</strong>.\n",
    "    <br><br>\n",
    "    <strong>P-box 1e</strong> and <strong>2e</strong> use ice-sheet projections from an emulator that accurately captures the output of both the GlacierMIP glacier model intercomparison and the ISMIP6 ice-sheet model intercomparison.\n",
    "    <br><br>\n",
    "    <strong>P-box 1e</strong> and <strong>1f</strong> both use multi-model intercomparison exercises \n",
    "    (<a href=\"https://www.nature.com/articles/s41586-021-03302-y\" style=\"color:blue; text-decoration:underline;\">ISMIP6</a> and <a href=\"https://doi.org/10.5194/esd-11-35-2020\" style=\"color:blue; text-decoration:underline;\">LARMIP2</a>). \n",
    "    These p-boxes represent a medium-to-high level of agreement among the participating models. The IPCC AR6 thus assessed medium confidence in their projections of included processes.\n",
    "</span>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"font-size:24pt; color:blue; font-family: 'Times New Roman';\"> Set <b>expFolder</b> ::\n",
    "    <span style=\"font-size:14pt; color:green;\"> point to where FACTS raw output is located (e.g. /facts/experiments) </span>\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "<span style=\"background-color: yellow;\"> need to modify for NZ and generic facts experiments </span> currently configured to the coupling syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "expFolder=\"/projects/kopp/facts-experiments/221217\"\n",
    "#\n",
    "region = 'global'\n",
    "#\n",
    "import fun_pbox_Gen_v3 as fn\n",
    "#\n",
    "ssps=[\"ssp119\",\"ssp126\",\"ssp245\",\"ssp370\",\"ssp585\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"font-size:24pt; color:blue; font-family: 'Times New Roman';\"> Generate::\n",
    "    <span style=\"font-size:14pt; color:green;\">Quantile files from FACTS output and arrange in workflow/ssp folders </span>\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_and_convert(source_file, dest_folder, region):\n",
    "    #shutil.copy2(source_file, dest_folder)\n",
    "    out_file_path = os.path.join(dest_folder, os.path.basename(source_file).split(\".nc\")[0] + \"_quantiles.nc\")\n",
    "    fn.Samples_to_Quantiles(source_file, out_file_path)\n",
    "\n",
    "path = fn.create_directory(\"1_workflow\",\"remove\")\n",
    "\n",
    "skip = {\n",
    "    'wf3e': ['ssp119', 'ssp370'],\n",
    "    'wf3f': ['ssp119', 'ssp370'],\n",
    "    'wf4':  ['ssp119', 'ssp245', 'ssp370']\n",
    "}\n",
    "\n",
    "for workflow, file_patterns in fn.WF_file_patterns.items():\n",
    "    for ssp in ssps:\n",
    "        if ssp in skip.get(workflow, []):\n",
    "            continue\n",
    "        \n",
    "        ssp_path = os.path.join(path, workflow, ssp)\n",
    "        os.makedirs(ssp_path, exist_ok=True)\n",
    "        \n",
    "        # Copy Component files & convert to Quantiles.\n",
    "        for file in file_patterns:\n",
    "            component_file_path = f'{expFolder}/coupling.{ssp}/output/coupling.{ssp}.{file}_{region}sl.nc'\n",
    "            copy_and_convert(component_file_path, ssp_path, region)\n",
    "        \n",
    "        # Copy Common files & convert to Quantiles.\n",
    "        for common_file_item in fn.common_files:\n",
    "            common_file_path = f'{expFolder}/coupling.{ssp}/output/coupling.{ssp}.{common_file_item}_{region}sl.nc'\n",
    "            copy_and_convert(common_file_path, ssp_path, region)\n",
    "        \n",
    "        # Copy Total files & convert to Quantiles.\n",
    "        total_file_path = f'{expFolder}/coupling.{ssp}/output/coupling.{ssp}.total.workflow.{workflow}.{region}.nc'\n",
    "        copy_and_convert(total_file_path, ssp_path, region)\n",
    "        \n",
    "        # Copy VLM file & convert to Quantiles.  \n",
    "        if region == 'local':\n",
    "            vlm_file_path = f'{expFolder}/coupling.{ssp}/output/coupling.{ssp}.{fn.local_files}.{region}sl.nc'\n",
    "            copy_and_convert(vlm_file_path, ssp_path, region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"font-size: 32pt; color: red; font-family: 'Times New Roman'\"> \n",
    "    Generate:: <br>\n",
    "    <ol style=\"font-size: 12pt; color: green; font-family: 'Times New Roman'\">\n",
    "    <li> Pbox files and folders</li>\n",
    "</ol>  \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_file_with_pattern = lambda ssp, wf, pattern: fn.copy_filename_with_pattern(f\"{os.getcwd()}/1_workflow/{wf}/{ssp}\", ssp_path, f\"*{pattern}*\")\n",
    "copy_all_wf_files = lambda p, s, d: fn.copy_all_files_from(os.path.join(os.getcwd(), f'1_workflow/wf{p.split(\"_\")[1]}/{s}'), d)\n",
    "#\n",
    "def process_pb_1(pbox, ssp_path, ssp):\n",
    "    patterns = {\n",
    "        'pb_1e': (\"emulandice.AIS\", \"larmip.AIS\", 'e'),\n",
    "        'pb_1f': (\"ipccar5.icesheets_AIS\", \"larmip.AIS\", 'f')\n",
    "    }\n",
    "    pattern1, pattern2, wf_suffix = patterns[pbox]\n",
    "    # AIS Pbox component\n",
    "    infiles = [f'{ssp_path}/{fn.find_filename_with_pattern(ssp_path, pattern)}' for pattern in (pattern1, pattern2)]\n",
    "    outfile = f\"{ssp_path}/icesheets-pb{pbox.split('_')[1]}-icesheets-{ssp}_AIS_globalsl.nc\"\n",
    "    fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "    \n",
    "    # Total\n",
    "    infiles = [f'{ssp_path}/{fn.find_filename_with_pattern(ssp_path, f\"total.workflow.wf{i}{wf_suffix}\")}' for i in (1, 2)]\n",
    "    outfile = f'{ssp_path}/total-workflow.nc'\n",
    "    fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "#\n",
    "#    \n",
    "def handle_component(ssp_path, patterns, outfile_prefix, pbox, ssp):\n",
    "    infiles = [f'{ssp_path}/{fn.find_filename_with_pattern(ssp_path, pattern)}' for pattern in patterns]\n",
    "    outfile = f\"{ssp_path}/{outfile_prefix}-pb{pbox.split('_')[1]}-{outfile_prefix.split('-')[1]}-{ssp}_globalsl.nc\"\n",
    "    fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "    \n",
    "configurations = {\n",
    "            'pb_2e': {\n",
    "                'copy_patterns': [('wf1e', 'emulandice.AIS'), ('wf3e', 'deconto21.AIS'), \n",
    "                                  ('wf4', 'bamber19.icesheets_AIS'), ('wf4', 'bamber19.icesheets_GIS'), \n",
    "                                  ('wf1f', 'ipccar5.glaciers')],\n",
    "                'ais_patterns': [\"emulandice.AIS\", \"larmip.AIS\", \"deconto21.AIS\", \"bamber19.icesheets_AIS\"],\n",
    "                'gis_patterns': [\"emulandice.GrIS\", \"bamber19.icesheets_GIS\"],\n",
    "                'glacier_patterns': [\"emulandice.glaciers\", \"ipccar5.glaciers\"],\n",
    "                'total_patterns': [\"total.workflow.wf2e\", \"total.workflow.wf1e\", \"total.workflow.wf3e\", \"total.workflow.wf4\"]\n",
    "            },\n",
    "            'pb_2f': {\n",
    "                'copy_patterns': [('wf1f', 'ipccar5.icesheets_AIS*'), ('wf3f', 'deconto21.AIS*'), \n",
    "                                  ('wf4', 'bamber19.icesheets_AIS*'), ('wf4', 'bamber19.icesheets_GIS')],\n",
    "                'ais_patterns': [\"ipccar5.icesheets_AIS\", \"larmip.AIS\", \"deconto21.AIS\", \"bamber19.icesheets_AIS\"],\n",
    "                'gis_patterns': [\"GrIS1f.FittedISMIP.GrIS\", \"bamber19.icesheets_GIS\"],\n",
    "                'total_patterns': [\"total.workflow.wf1f\", \"total.workflow.wf2f\", \"total.workflow.wf3f\", \"total.workflow.wf4\"]\n",
    "            }\n",
    "}    \n",
    "    \n",
    "    \n",
    "#\n",
    "path = fn.create_directory(\"2_pbox_oldVersion\",\"remove\")\n",
    "#\n",
    "for pbox in fn.PB_file_patterns:\n",
    "    os.makedirs(os.path.join(path, pbox), exist_ok=True)\n",
    "    for ssp in ssps:\n",
    "        # ..............................................................................\n",
    "        if pbox in ['pb_2e', 'pb_2f'] and ssp in['ssp119','ssp245','ssp370']: continue\n",
    "        # ..............................................................................\n",
    "        ssp_path = fn.create_directory(f'{os.path.join(path, pbox,ssp)}',\"remove\")\n",
    "        # \n",
    "        if pbox in ['pb_1e','pb_1f']:\n",
    "            copy_all_wf_files(pbox, ssp, ssp_path) \n",
    "            copy_file_with_pattern(ssp, 'wf2e', 'larmip.AIS')\n",
    "            #\n",
    "            if pbox in ['pb_1e', 'pb_1f']:\n",
    "            process_pb_1(pbox, ssp_path, ssp)\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        # ---> shrink below\n",
    "        if pbox in configurations:\n",
    "            config = configurations[pbox]\n",
    "            copy_all_wf_files(pbox, ssp, ssp_path)\n",
    "            #\n",
    "            for suffix, pattern in config['copy_patterns']:\n",
    "                copy_file_with_pattern(ssp, suffix, pattern)\n",
    "            #\n",
    "            handle_component(ssp_path, config['ais_patterns'], \"icesheets-AIS\", pbox, ssp)\n",
    "            handle_component(ssp_path, config['gis_patterns'], \"icesheets-GIS\", pbox, ssp)\n",
    "            if pbox in ['pb_2e']: handle_component(ssp_path, config['glacier_patterns'], \"glaciers\", pbox, ssp)\n",
    "            handle_component(ssp_path, config['total_patterns'], \"total-workflow\", pbox, ssp)\n",
    "\n",
    "            # Uncomment below if you want to delete files\n",
    "            # for pattern1, pattern2 in [(\"*AIS*\", \"icesheets-pb*\"), (\"*GIS*\", \"icesheets-pb*\"), (\"*glaciers*\", \"glaciers-pb*\"), (\"*total*\", \"*-workflow*\")]:\n",
    "            #     fn.delete_files_with_pattern(ssp_path, pattern1, pattern2)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (1449892312.py, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [3], line 36\u001b[0;36m\u001b[0m\n\u001b[0;31m    process_pb_1(pbox, ssp_path, ssp)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "copy_file_with_pattern = lambda ssp, wf, pattern: fn.copy_filename_with_pattern(f\"{os.getcwd()}/1_workflow/{wf}/{ssp}\", ssp_path, f\"*{pattern}*\")\n",
    "copy_all_wf_files = lambda p, s, d: fn.copy_all_files_from(os.path.join(os.getcwd(), f'1_workflow/wf{p.split(\"_\")[1]}/{s}'), d)\n",
    "#\n",
    "def process_pb_1(pbox, ssp_path, ssp):\n",
    "    patterns = {\n",
    "        'pb_1e': (\"emulandice.AIS\", \"larmip.AIS\", 'e'),\n",
    "        'pb_1f': (\"ipccar5.icesheets_AIS\", \"larmip.AIS\", 'f')\n",
    "    }\n",
    "    pattern1, pattern2, wf_suffix = patterns[pbox]\n",
    "    # AIS Pbox component\n",
    "    infiles = [f'{ssp_path}/{fn.find_filename_with_pattern(ssp_path, pattern)}' for pattern in (pattern1, pattern2)]\n",
    "    outfile = f\"{ssp_path}/icesheets-pb{pbox.split('_')[1]}-icesheets-{ssp}_AIS_globalsl.nc\"\n",
    "    fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "    \n",
    "    # Total\n",
    "    infiles = [f'{ssp_path}/{fn.find_filename_with_pattern(ssp_path, f\"total.workflow.wf{i}{wf_suffix}\")}' for i in (1, 2)]\n",
    "    outfile = f'{ssp_path}/total-workflow.nc'\n",
    "    fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "#\n",
    "#    \n",
    "def handle_component(ssp_path, patterns, outfile_prefix, pbox, ssp):\n",
    "    infiles = [f'{ssp_path}/{fn.find_filename_with_pattern(ssp_path, pattern)}' for pattern in patterns]\n",
    "    outfile = f\"{ssp_path}/{outfile_prefix}-pb{pbox.split('_')[1]}-{outfile_prefix.split('-')[1]}-{ssp}_globalsl.nc\"\n",
    "    fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#\n",
    "path = fn.create_directory(\"2_pbox_oldVersion\",\"remove\")\n",
    "#\n",
    "for pbox in fn.PB_file_patterns:\n",
    "    os.makedirs(os.path.join(path, pbox), exist_ok=True)\n",
    "    for ssp in ssps:\n",
    "        # ..............................................................................\n",
    "        if pbox in ['pb_2e', 'pb_2f'] and ssp in['ssp119','ssp245','ssp370']: continue\n",
    "        # ..............................................................................\n",
    "        ssp_path = fn.create_directory(f'{os.path.join(path, pbox,ssp)}',\"remove\")\n",
    "        # \n",
    "        if pbox in ['pb_1e','pb_1f']:\n",
    "            copy_all_wf_files(pbox, ssp, ssp_path) \n",
    "            copy_file_with_pattern(ssp, 'wf2e', 'larmip.AIS')\n",
    "            #\n",
    "            if pbox in ['pb_1e', 'pb_1f']:\n",
    "            process_pb_1(pbox, ssp_path, ssp)\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        # ---> shrink below\n",
    "        #\n",
    "        if pbox in ['pb_2e']:\n",
    "            # Copy files\n",
    "            copy_all_wf_files(pbox, ssp, ssp_path)\n",
    "            for suffix, pattern in [('wf1e', 'emulandice.AIS'), ('wf3e', 'deconto21.AIS'), ('wf4', 'bamber19.icesheets_AIS'), \n",
    "                                    ('wf4', 'bamber19.icesheets_GIS'), ('wf1f', 'ipccar5.glaciers'), \n",
    "                                    ('wf1e', 'total.workflow'), ('wf3e', 'total.workflow'), ('wf4', 'total.workflow')]:\n",
    "                copy_file_with_pattern(ssp, suffix, pattern)\n",
    "        \n",
    "            # Handle AIS Pbox component\n",
    "            handle_component(ssp_path, [\"emulandice.AIS\", \"larmip.AIS\", \"deconto21.AIS\", \"bamber19.icesheets_AIS\"], \n",
    "                             \"icesheets-AIS\", pbox, ssp)\n",
    "            \n",
    "            # Handle GIS Pbox component\n",
    "            handle_component(ssp_path, [\"emulandice.GrIS\", \"bamber19.icesheets_GIS\"], \"icesheets-GIS\", pbox, ssp)\n",
    "            \n",
    "            # Handle Glaciers Pbox component\n",
    "            handle_component(ssp_path, [\"emulandice.glaciers\", \"ipccar5.glaciers\"], \"glaciers\", pbox, ssp)\n",
    "        \n",
    "            # Handle total\n",
    "            handle_component(ssp_path, [\"total.workflow.wf2e\", \"total.workflow.wf1e\", \"total.workflow.wf3e\", \"total.workflow.wf4\"], \n",
    "                             \"total-workflow\", pbox, ssp)\n",
    "        \n",
    "            # Uncomment below if you want to delete files\n",
    "            # for pattern1, pattern2 in [(\"*AIS*\", \"icesheets-pb*\"), (\"*GIS*\", \"icesheets-pb*\"), (\"*glaciers*\", \"glaciers-pb*\"), \n",
    "            #                            (\"*total*\", \"*-workflow*\")]:\n",
    "            #     fn.delete_files_with_pattern(ssp_path, pattern1, pattern2)\n",
    "                #\n",
    "        #\n",
    "        #\n",
    "        #        \n",
    "        if pbox in ['pb_2f']:\n",
    "            copy_all_wf_files(pbox, ssp, ssp_path) \n",
    "            # Also copy\n",
    "            copy_file_with_pattern(ssp, 'wf1f', 'ipccar5.icesheets_AIS*');\n",
    "            copy_file_with_pattern(ssp, 'wf3f', 'deconto21.AIS*')\n",
    "            copy_file_with_pattern(ssp, 'wf4' , 'bamber19.icesheets_AIS*');\n",
    "            copy_file_with_pattern(ssp, 'wf4' , 'bamber19.icesheets_GIS')\n",
    "            #\n",
    "            # AIS Pbox component\n",
    "            fname1=fn.find_filename_with_pattern(ssp_path,\"ipccar5.icesheets_AIS\")\n",
    "            fname2=fn.find_filename_with_pattern(ssp_path,\"larmip.AIS\")\n",
    "            fname3=fn.find_filename_with_pattern(ssp_path,\"deconto21.AIS\")\n",
    "            fname4=fn.find_filename_with_pattern(ssp_path,\"bamber19.icesheets_AIS\")\n",
    "            infiles=[f'{ssp_path}/{fname1}' , f'{ssp_path}/{fname2}', f'{ssp_path}/{fname3}' , f'{ssp_path}/{fname4}']\n",
    "            outfile = f\"{ssp_path}/icesheets-pb{pbox.split('_')[1]}-icesheets-{ssp}_AIS_globalsl.nc\"\n",
    "            fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "            #   \n",
    "            # GIS Pbox component\n",
    "            fname1=fn.find_filename_with_pattern(ssp_path,\"GrIS1f.FittedISMIP.GrIS\")\n",
    "            fname2=fn.find_filename_with_pattern(ssp_path,\"bamber19.icesheets_GIS\")\n",
    "            infiles=[f'{ssp_path}/{fname1}' , f'{ssp_path}/{fname2}']\n",
    "            outfile = f\"{ssp_path}/icesheets-pb{pbox.split('_')[1]}-icesheets-{ssp}_GIS_globalsl.nc\"\n",
    "            fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)   \n",
    "            #\n",
    "            # total\n",
    "            copy_file_with_pattern(ssp, 'wf1f', 'total.workflow')\n",
    "            copy_file_with_pattern(ssp, 'wf3f', 'total.workflow')\n",
    "            copy_file_with_pattern(ssp, 'wf4' , 'total.workflow') \n",
    "            fname1=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf1f\");               \n",
    "            fname2=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf2f\"); \n",
    "            fname3=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf3f\"); \n",
    "            fname4=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf4\")\n",
    "            infiles=[f'{ssp_path}/{fname1}' , f'{ssp_path}/{fname2}', f'{ssp_path}/{fname3}', f'{ssp_path}/{fname4}']; \n",
    "            outfile=f'{ssp_path}/total-workflow.nc'\n",
    "            fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "            #\n",
    "#             fn.delete_files_with_pattern(ssp_path, \"*AIS*\", \"icesheets-pb*\")\n",
    "#             fn.delete_files_with_pattern(ssp_path, \"*GIS*\", \"icesheets-pb*\")\n",
    "#             fn.delete_files_with_pattern(ssp_path, \"*total*\", \"*-workflow*\")            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_file_with_pattern = lambda ssp, wf, pattern: fn.copy_filename_with_pattern(f\"{os.getcwd()}/1_workflow/{wf}/{ssp}\", ssp_path, f\"*{pattern}*\")\n",
    "copy_all_wf_files = lambda p, s, d: fn.copy_all_files_from(os.path.join(os.getcwd(), f'1_workflow/wf{p.split(\"_\")[1]}/{s}'), d)\n",
    "valid_file = lambda filename: filename and os.path.isfile(filename) and filename != 'None'\n",
    "path = fn.create_directory(\"2_pbox\")\n",
    "\n",
    "file_patterns = {\n",
    "    'AIS': [\"emulandice.AIS\", \"larmip.AIS\", \"deconto21.AIS\", \"bamber19.icesheets_AIS\"],\n",
    "    'GIS': [\"emulandice.GrIS\", \"bamber19.icesheets_GIS\"],\n",
    "    'glaciers': [\"emulandice.glaciers\", \"ipccar5.glaciers\"],\n",
    "    'total': [\"total.workflow.wf1e\", \"total.workflow.wf2e\", \"total.workflow.wf3e\", \"total.workflow.wf4\"]\n",
    "}\n",
    "\n",
    "for pbox in fn.PB_file_patterns:\n",
    "    os.makedirs(os.path.join(path, pbox), exist_ok=True)\n",
    "\n",
    "    for ssp in ssps:\n",
    "        if pbox in ['pb_2e', 'pb_2f'] and ssp in ['ssp119', 'ssp245', 'ssp370']:\n",
    "            continue\n",
    "\n",
    "        ssp_path = os.path.join(path, pbox, ssp)\n",
    "        os.makedirs(ssp_path, exist_ok=True)\n",
    "\n",
    "        if pbox in ['pb_1e', 'pb_1f']:\n",
    "            copy_all_wf_files(pbox, ssp, ssp_path)\n",
    "            copy_file_with_pattern(ssp, 'wf2e', 'larmip.AIS')\n",
    "\n",
    "        if pbox in ['pb_1e', 'pb_1f', 'pb_2e', 'pb_2f']:\n",
    "            component_types = ['AIS'] if pbox in ['pb_1e', 'pb_1f'] else ['AIS', 'GIS', 'glaciers', 'total']\n",
    "            \n",
    "            for comp_type in component_types:\n",
    "                infiles = [f'{ssp_path}/{fn.find_filename_with_pattern(ssp_path, pattern)}' for pattern in file_patterns[comp_type] if valid_file(f'{ssp_path}/{fn.find_filename_with_pattern(ssp_path, pattern)}')]\n",
    "\n",
    "                if infiles:\n",
    "                    outfile = f\"{ssp_path}/{comp_type}-pb{pbox.split('_')[1]}-{comp_type}-{ssp}_globalsl.nc\"\n",
    "                    fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "#                     fn.delete_files_with_pattern(ssp_path, f\"*{comp_type}*\", f\"{comp_type}-pb*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"font-size: 32pt; color: red; font-family: 'Times New Roman'\"> \n",
    "    Generate:: <br>\n",
    "    <ol style=\"font-size: 12pt; color: green; font-family: 'Times New Roman'\">\n",
    "    <li> Confidence level files files and folders</li>\n",
    "</ol>  \n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = fn.create_directory(\"3_confidence_level_files\",,\"remove\")\n",
    "fn.generate_confidence_files(os.getcwd()+'/2_pbox', path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
