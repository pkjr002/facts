{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24pt; color:blue; font-family: 'Times New Roman'\">P-box Notebook \n",
    "    <span style=\"color:green;\"> for creating AR6 style P-box data </span>\n",
    "</span>\n",
    "<br>\n",
    "<span style=\"font-size:12pt; color:black; font-family:Georgia, serif;font-style:italic\">by Praveen Kumar and Robert Kopp.</span>\n",
    "<br>\n",
    "<br>\n",
    "<span style=\"font-family: 'Times New Roman'; font-size:16pt; color:black\"> \n",
    "    This is a notebook that can be used to create and vizualize P-box data from raw <a href=\"https://doi.org/10.5194/egusphere-2023-14\" style=\"color:blue; text-decoration:underline;\">FACTS 1.0</a>\n",
    "    output. Workflows and associated *.nc files are created as part of this notebook. \n",
    "<br>\n",
    "<br>\n",
    "<span style=\"font-family:'Courier New', monospace; font-size:12pt; color:black\"> <b>Background::</b> <br>\n",
    "    In order to represent deep uncertainty, Probability boxes (p-boxes) can be constructed. These represent an envelope encompassing alternative probability distributions for describing the same variables. Within this notebook, we construct four p-boxes: <strong>1e, 1f, 2e,</strong> and <strong>2f</strong>.\n",
    "    <br><br>\n",
    "    <strong>P-box 1e</strong> and <strong>2e</strong> use ice-sheet projections from an emulator that accurately captures the output of both the GlacierMIP glacier model intercomparison and the ISMIP6 ice-sheet model intercomparison.\n",
    "    <br><br>\n",
    "    <strong>P-box 1e</strong> and <strong>1f</strong> both use multi-model intercomparison exercises \n",
    "    (<a href=\"https://www.nature.com/articles/s41586-021-03302-y\" style=\"color:blue; text-decoration:underline;\">ISMIP6</a> and <a href=\"https://doi.org/10.5194/esd-11-35-2020\" style=\"color:blue; text-decoration:underline;\">LARMIP2</a>). \n",
    "    These p-boxes represent a medium-to-high level of agreement among the participating models. The IPCC AR6 thus assessed medium confidence in their projections of included processes.\n",
    "</span>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"font-size:24pt; color:blue; font-family: 'Times New Roman';\"> Set <b>expFolder</b> ::\n",
    "    <span style=\"font-size:14pt; color:green;\"> point to where FACTS raw output is located (e.g. /facts/experiments) </span>\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "<span style=\"background-color: yellow;\"> need to modify for NZ and generic facts experiments </span> currently configured to the coupling syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "expFolder=\"/projects/kopp/facts-experiments/221217\"\n",
    "#\n",
    "region = 'global'\n",
    "#\n",
    "import fun_pbox_Gen_v3 as fn\n",
    "#\n",
    "ssps=[\"ssp119\",\"ssp126\",\"ssp245\",\"ssp370\",\"ssp585\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"font-size:24pt; color:blue; font-family: 'Times New Roman';\"> Generate::\n",
    "    <span style=\"font-size:14pt; color:green;\">Quantile files from FACTS output and arrange in workflow/ssp folders </span>\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_and_convert(source_file, dest_folder, region):\n",
    "    #shutil.copy2(source_file, dest_folder)\n",
    "    out_file_path = os.path.join(dest_folder, os.path.basename(source_file).split(\".nc\")[0] + \"_quantiles.nc\")\n",
    "    fn.Samples_to_Quantiles(source_file, out_file_path)\n",
    "\n",
    "path = fn.create_directory(\"1_workflow\",\"remove\")\n",
    "\n",
    "skip = {\n",
    "    'wf3e': ['ssp119', 'ssp370'],\n",
    "    'wf3f': ['ssp119', 'ssp370'],\n",
    "    'wf4':  ['ssp119', 'ssp245', 'ssp370']\n",
    "}\n",
    "\n",
    "for workflow, file_patterns in fn.WF_file_patterns.items():\n",
    "    for ssp in ssps:\n",
    "        if ssp in skip.get(workflow, []):\n",
    "            continue\n",
    "        \n",
    "        ssp_path = os.path.join(path, workflow, ssp)\n",
    "        os.makedirs(ssp_path, exist_ok=True)\n",
    "        \n",
    "        # Copy Component files & convert to Quantiles.\n",
    "        for file in file_patterns:\n",
    "            component_file_path = f'{expFolder}/coupling.{ssp}/output/coupling.{ssp}.{file}_{region}sl.nc'\n",
    "            copy_and_convert(component_file_path, ssp_path, region)\n",
    "        \n",
    "        # Copy Common files & convert to Quantiles.\n",
    "        for common_file_item in fn.common_files:\n",
    "            common_file_path = f'{expFolder}/coupling.{ssp}/output/coupling.{ssp}.{common_file_item}_{region}sl.nc'\n",
    "            copy_and_convert(common_file_path, ssp_path, region)\n",
    "        \n",
    "        # Copy Total files & convert to Quantiles.\n",
    "        total_file_path = f'{expFolder}/coupling.{ssp}/output/coupling.{ssp}.total.workflow.{workflow}.{region}.nc'\n",
    "        copy_and_convert(total_file_path, ssp_path, region)\n",
    "        \n",
    "        # Copy VLM file & convert to Quantiles.  \n",
    "        if region == 'local':\n",
    "            vlm_file_path = f'{expFolder}/coupling.{ssp}/output/coupling.{ssp}.{fn.local_files}.{region}sl.nc'\n",
    "            copy_and_convert(vlm_file_path, ssp_path, region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"font-size: 32pt; color: red; font-family: 'Times New Roman'\"> \n",
    "    Generate:: <br>\n",
    "    <ol style=\"font-size: 12pt; color: green; font-family: 'Times New Roman'\">\n",
    "    <li> Pbox files and folders</li>\n",
    "</ol>  \n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/scratch/pk695/FACTS/002_fork/facts/JupNbk/000_pk-JupNb_TESTspace/updated_GMD_nbk/notebooks_OG/P-box/2_pbox/pb_1e/ssp119/coupling.ssp119.total.workflow.wf1e.global_quantiles.nc', '/scratch/pk695/FACTS/002_fork/facts/JupNbk/000_pk-JupNb_TESTspace/updated_GMD_nbk/notebooks_OG/P-box/2_pbox/pb_1e/ssp119/None']\n",
      "['/scratch/pk695/FACTS/002_fork/facts/JupNbk/000_pk-JupNb_TESTspace/updated_GMD_nbk/notebooks_OG/P-box/2_pbox/pb_1e/ssp126/coupling.ssp126.total.workflow.wf1e.global_quantiles.nc', '/scratch/pk695/FACTS/002_fork/facts/JupNbk/000_pk-JupNb_TESTspace/updated_GMD_nbk/notebooks_OG/P-box/2_pbox/pb_1e/ssp126/None']\n",
      "['/scratch/pk695/FACTS/002_fork/facts/JupNbk/000_pk-JupNb_TESTspace/updated_GMD_nbk/notebooks_OG/P-box/2_pbox/pb_1e/ssp245/coupling.ssp245.total.workflow.wf1e.global_quantiles.nc', '/scratch/pk695/FACTS/002_fork/facts/JupNbk/000_pk-JupNb_TESTspace/updated_GMD_nbk/notebooks_OG/P-box/2_pbox/pb_1e/ssp245/None']\n",
      "['/scratch/pk695/FACTS/002_fork/facts/JupNbk/000_pk-JupNb_TESTspace/updated_GMD_nbk/notebooks_OG/P-box/2_pbox/pb_1e/ssp370/coupling.ssp370.total.workflow.wf1e.global_quantiles.nc', '/scratch/pk695/FACTS/002_fork/facts/JupNbk/000_pk-JupNb_TESTspace/updated_GMD_nbk/notebooks_OG/P-box/2_pbox/pb_1e/ssp370/None']\n",
      "['/scratch/pk695/FACTS/002_fork/facts/JupNbk/000_pk-JupNb_TESTspace/updated_GMD_nbk/notebooks_OG/P-box/2_pbox/pb_1e/ssp585/coupling.ssp585.total.workflow.wf1e.global_quantiles.nc', '/scratch/pk695/FACTS/002_fork/facts/JupNbk/000_pk-JupNb_TESTspace/updated_GMD_nbk/notebooks_OG/P-box/2_pbox/pb_1e/ssp585/None']\n"
     ]
    }
   ],
   "source": [
    "copy_file_with_pattern = lambda ssp, wf, pattern: fn.copy_filename_with_pattern(f\"{os.getcwd()}/1_workflow/{wf}/{ssp}\", ssp_path, f\"*{pattern}*\")\n",
    "copy_all_wf_files = lambda p, s, d: fn.copy_all_files_from(os.path.join(os.getcwd(), f'1_workflow/wf{p.split(\"_\")[1]}/{s}'), d)\n",
    "#\n",
    "def process_pb_1(pbox, ssp_path, ssp):\n",
    "    patterns = {\n",
    "        'pb_1e': (\"emulandice.AIS\", \"larmip.AIS\", 'e'),\n",
    "        'pb_1f': (\"ipccar5.icesheets_AIS\", \"larmip.AIS\", 'f')\n",
    "    }\n",
    "    pattern1, pattern2, wf_suffix = patterns[pbox]\n",
    "    # AIS Pbox component\n",
    "    infiles = [f'{ssp_path}/{fn.find_filename_with_pattern(ssp_path, pattern)}' for pattern in (pattern1, pattern2)]\n",
    "    outfile = f\"{ssp_path}/icesheets-pb{pbox.split('_')[1]}-icesheets-{ssp}_AIS_globalsl.nc\"\n",
    "    fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "    \n",
    "    # Total\n",
    "    infiles = [f'{ssp_path}/{fn.find_filename_with_pattern(ssp_path, f\"total.workflow.wf{i}{wf_suffix}\")}' for i in (1, 2)]\n",
    "    outfile = f'{ssp_path}/total-workflow.nc'\n",
    "    print(infiles)\n",
    "#     fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "#\n",
    "path = fn.create_directory(\"2_pbox\",\"remove\")\n",
    "#\n",
    "for pbox in fn.PB_file_patterns:\n",
    "    os.makedirs(os.path.join(path, pbox), exist_ok=True)\n",
    "    for ssp in ssps:\n",
    "        # ..............................................................................\n",
    "        if pbox in ['pb_2e', 'pb_2f'] and ssp in['ssp119','ssp245','ssp370']: continue\n",
    "        # ..............................................................................\n",
    "        ssp_path = fn.create_directory(f'{os.path.join(path, pbox,ssp)}')\n",
    "        # \n",
    "        if pbox in ['pb_1e']:\n",
    "            copy_all_wf_files(pbox, ssp, ssp_path) \n",
    "            copy_file_with_pattern(ssp, 'wf2e', 'larmip.AIS')\n",
    "            #\n",
    "            if pbox in ['pb_1e']:\n",
    "                process_pb_1(pbox, ssp_path, ssp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/scratch/pk695/FACTS/002_fork/facts/JupNbk/000_pk-JupNb_TESTspace/updated_GMD_nbk/notebooks_OG/P-box/2_pbox/pb_1e/ssp119/None'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/000_swre/miniconda/envs/plot/lib/python3.9/site-packages/xarray/backends/file_manager.py:210\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/000_swre/miniconda/envs/plot/lib/python3.9/site-packages/xarray/backends/lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/scratch/pk695/FACTS/002_fork/facts/JupNbk/000_pk-JupNb_TESTspace/updated_GMD_nbk/notebooks_OG/P-box/2_pbox/pb_1e/ssp119/None',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), 'd57cc737-b302-461b-af9c-6c51fa7df5c6']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pbox \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpb_1e\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpb_1f\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mprocess_pb_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssp_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# ---> shrink below\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pbox \u001b[38;5;129;01min\u001b[39;00m configurations:\n",
      "Cell \u001b[0;32mIn [7], line 18\u001b[0m, in \u001b[0;36mprocess_pb_1\u001b[0;34m(pbox, ssp_path, ssp)\u001b[0m\n\u001b[1;32m     16\u001b[0m infiles \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mssp_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;241m.\u001b[39mfind_filename_with_pattern(ssp_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal.workflow.wf\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mwf_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)]\n\u001b[1;32m     17\u001b[0m outfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mssp_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/total-workflow.nc\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_pbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpyear_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2020\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpyear_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpyear_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/pk695/FACTS/002_fork/facts/JupNbk/000_pk-JupNb_TESTspace/updated_GMD_nbk/notebooks_OG/P-box/fun_pbox_Gen_v3.py:172\u001b[0m, in \u001b[0;36mgenerate_pbox\u001b[0;34m(infiles, outfile, pyear_start, pyear_end, pyear_step)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_pbox\u001b[39m(infiles, outfile, pyear_start, pyear_end, pyear_step):\n\u001b[1;32m    171\u001b[0m     years \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(pyear_start, pyear_end\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, pyear_step)\n\u001b[0;32m--> 172\u001b[0m     component_data, varname, varunit, varscale, ids, lats, lons, qvar \u001b[38;5;241m=\u001b[39m \u001b[43mload_infiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myears\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \t\u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     median_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mflatnonzero(qvar \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[0;32m/scratch/pk695/FACTS/002_fork/facts/JupNbk/000_pk-JupNb_TESTspace/updated_GMD_nbk/notebooks_OG/P-box/fun_pbox_Gen_v3.py:164\u001b[0m, in \u001b[0;36mload_infiles\u001b[0;34m(infiles, years)\u001b[0m\n\u001b[1;32m    162\u001b[0m \t\u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m infile \u001b[38;5;129;01min\u001b[39;00m infiles:\n\u001b[0;32m--> 164\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnetcdf4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ds:\n\u001b[1;32m    165\u001b[0m             localsl_q\u001b[38;5;241m.\u001b[39mappend(ds[varname]\u001b[38;5;241m.\u001b[39msel(years\u001b[38;5;241m=\u001b[39myears)\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m    166\u001b[0m \t\u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m~/000_swre/miniconda/envs/plot/lib/python3.9/site-packages/xarray/backends/api.py:526\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    515\u001b[0m     decode_cf,\n\u001b[1;32m    516\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    523\u001b[0m )\n\u001b[1;32m    525\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 526\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    533\u001b[0m     backend_ds,\n\u001b[1;32m    534\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    543\u001b[0m )\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/000_swre/miniconda/envs/plot/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:577\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    559\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    574\u001b[0m     autoclose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    575\u001b[0m ):\n\u001b[1;32m    576\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 577\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mNetCDF4DataStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m~/000_swre/miniconda/envs/plot/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:382\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    376\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    377\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[1;32m    378\u001b[0m )\n\u001b[1;32m    379\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    380\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    381\u001b[0m )\n\u001b[0;32m--> 382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/000_swre/miniconda/envs/plot/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:329\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m~/000_swre/miniconda/envs/plot/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:391\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/000_swre/miniconda/envs/plot/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:385\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[1;32m    386\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/000_swre/miniconda/envs/plot/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/000_swre/miniconda/envs/plot/lib/python3.9/site-packages/xarray/backends/file_manager.py:198\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m~/000_swre/miniconda/envs/plot/lib/python3.9/site-packages/xarray/backends/file_manager.py:216\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    214\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    215\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 216\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2463\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2026\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/scratch/pk695/FACTS/002_fork/facts/JupNbk/000_pk-JupNb_TESTspace/updated_GMD_nbk/notebooks_OG/P-box/2_pbox/pb_1e/ssp119/None'"
     ]
    }
   ],
   "source": [
    "copy_file_with_pattern = lambda ssp, wf, pattern: fn.copy_filename_with_pattern(f\"{os.getcwd()}/1_workflow/{wf}/{ssp}\", ssp_path, f\"*{pattern}*\")\n",
    "copy_all_wf_files = lambda p, s, d: fn.copy_all_files_from(os.path.join(os.getcwd(), f'1_workflow/wf{p.split(\"_\")[1]}/{s}'), d)\n",
    "#\n",
    "def process_pb_1(pbox, ssp_path, ssp):\n",
    "    patterns = {\n",
    "        'pb_1e': (\"emulandice.AIS\", \"larmip.AIS\", 'e'),\n",
    "        'pb_1f': (\"ipccar5.icesheets_AIS\", \"larmip.AIS\", 'f')\n",
    "    }\n",
    "    pattern1, pattern2, wf_suffix = patterns[pbox]\n",
    "    # AIS Pbox component\n",
    "    infiles = [f'{ssp_path}/{fn.find_filename_with_pattern(ssp_path, pattern)}' for pattern in (pattern1, pattern2)]\n",
    "    outfile = f\"{ssp_path}/icesheets-pb{pbox.split('_')[1]}-icesheets-{ssp}_AIS_globalsl.nc\"\n",
    "    fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "    \n",
    "    # Total\n",
    "    infiles = [f'{ssp_path}/{fn.find_filename_with_pattern(ssp_path, f\"total.workflow.wf{i}{wf_suffix}\")}' for i in (1, 2)]\n",
    "    outfile = f'{ssp_path}/total-workflow.nc'\n",
    "    fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "#\n",
    "#    \n",
    "def handle_component(ssp_path, patterns, outfile_prefix, pbox, ssp):\n",
    "    infiles = [f'{ssp_path}/{fn.find_filename_with_pattern(ssp_path, pattern)}' for pattern in patterns]\n",
    "    outfile = f\"{ssp_path}/{outfile_prefix}-pb{pbox.split('_')[1]}-{outfile_prefix.split('-')[1]}-{ssp}_globalsl.nc\"\n",
    "    fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "    \n",
    "configurations = {\n",
    "            'pb_2e': {\n",
    "                'copy_patterns': [('wf1e', 'emulandice.AIS'), ('wf3e', 'deconto21.AIS'), \n",
    "                                  ('wf4', 'bamber19.icesheets_AIS'), ('wf4', 'bamber19.icesheets_GIS'), \n",
    "                                  ('wf1f', 'ipccar5.glaciers')],\n",
    "                'ais_patterns': [\"emulandice.AIS\", \"larmip.AIS\", \"deconto21.AIS\", \"bamber19.icesheets_AIS\"],\n",
    "                'gis_patterns': [\"emulandice.GrIS\", \"bamber19.icesheets_GIS\"],\n",
    "                'glacier_patterns': [\"emulandice.glaciers\", \"ipccar5.glaciers\"],\n",
    "                'total_patterns': [\"total.workflow.wf2e\", \"total.workflow.wf1e\", \"total.workflow.wf3e\", \"total.workflow.wf4\"]\n",
    "            },\n",
    "            'pb_2f': {\n",
    "                'copy_patterns': [('wf1f', 'ipccar5.icesheets_AIS*'), ('wf3f', 'deconto21.AIS*'), \n",
    "                                  ('wf4', 'bamber19.icesheets_AIS*'), ('wf4', 'bamber19.icesheets_GIS')],\n",
    "                'ais_patterns': [\"ipccar5.icesheets_AIS\", \"larmip.AIS\", \"deconto21.AIS\", \"bamber19.icesheets_AIS\"],\n",
    "                'gis_patterns': [\"GrIS1f.FittedISMIP.GrIS\", \"bamber19.icesheets_GIS\"],\n",
    "                'total_patterns': [\"total.workflow.wf1f\", \"total.workflow.wf2f\", \"total.workflow.wf3f\", \"total.workflow.wf4\"]\n",
    "            }\n",
    "}    \n",
    "    \n",
    "    \n",
    "#\n",
    "path = fn.create_directory(\"2_pbox\",\"remove\")\n",
    "#\n",
    "for pbox in fn.PB_file_patterns:\n",
    "    os.makedirs(os.path.join(path, pbox), exist_ok=True)\n",
    "    for ssp in ssps:\n",
    "        # ..............................................................................\n",
    "        if pbox in ['pb_2e', 'pb_2f'] and ssp in['ssp119','ssp245','ssp370']: continue\n",
    "        # ..............................................................................\n",
    "        ssp_path = fn.create_directory(f'{os.path.join(path, pbox,ssp)}')\n",
    "        # \n",
    "        if pbox in ['pb_1e','pb_1f']:\n",
    "            copy_all_wf_files(pbox, ssp, ssp_path) \n",
    "            copy_file_with_pattern(ssp, 'wf2e', 'larmip.AIS')\n",
    "            #\n",
    "            if pbox in ['pb_1e', 'pb_1f']:\n",
    "                process_pb_1(pbox, ssp_path, ssp)\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        # ---> shrink below\n",
    "        if pbox in configurations:\n",
    "            config = configurations[pbox]\n",
    "            copy_all_wf_files(pbox, ssp, ssp_path)\n",
    "            #\n",
    "            for suffix, pattern in config['copy_patterns']:\n",
    "                copy_file_with_pattern(ssp, suffix, pattern)\n",
    "            #\n",
    "            handle_component(ssp_path, config['ais_patterns'], \"icesheets-AIS\", pbox, ssp)\n",
    "            handle_component(ssp_path, config['gis_patterns'], \"icesheets-GIS\", pbox, ssp)\n",
    "            if pbox in ['pb_2e']: handle_component(ssp_path, config['glacier_patterns'], \"glaciers\", pbox, ssp)\n",
    "            handle_component(ssp_path, config['total_patterns'], \"total-workflow\", pbox, ssp)\n",
    "\n",
    "            # Uncomment below if you want to delete files\n",
    "            # for pattern1, pattern2 in [(\"*AIS*\", \"icesheets-pb*\"), (\"*GIS*\", \"icesheets-pb*\"), (\"*glaciers*\", \"glaciers-pb*\"), (\"*total*\", \"*-workflow*\")]:\n",
    "            #     fn.delete_files_with_pattern(ssp_path, pattern1, pattern2)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_file_with_pattern = lambda ssp, wf, pattern: fn.copy_filename_with_pattern(f\"{os.getcwd()}/1_workflow/{wf}/{ssp}\", ssp_path, f\"*{pattern}*\")\n",
    "copy_all_wf_files = lambda p, s, d: fn.copy_all_files_from(os.path.join(os.getcwd(), f'1_workflow/wf{p.split(\"_\")[1]}/{s}'), d)\n",
    "#\n",
    "#\n",
    "path = fn.create_directory(\"2_pbox_old_version\",\"remove\")\n",
    "#\n",
    "for pbox in fn.PB_file_patterns:\n",
    "    os.makedirs(os.path.join(path, pbox), exist_ok=True)\n",
    "    for ssp in ssps:\n",
    "        # ..............................................................................\n",
    "        if pbox in ['pb_2e', 'pb_2f'] and ssp in['ssp119','ssp245','ssp370']: continue\n",
    "        # ..............................................................................\n",
    "        ssp_path = fn.create_directory(f'{os.path.join(path, pbox,ssp)}')\n",
    "        #\n",
    "        # \n",
    "        if pbox in ['pb_1e','pb_1f']:\n",
    "            copy_all_wf_files(pbox, ssp, ssp_path) \n",
    "            # also copy\n",
    "            copy_file_with_pattern(ssp, 'wf2e', 'larmip.AIS')\n",
    "            #\n",
    "            #\n",
    "            if pbox in ['pb_1e']:\n",
    "                #\n",
    "                # AIS Pbox component\n",
    "                fname1=fn.find_filename_with_pattern(ssp_path,\"emulandice.AIS\")\n",
    "                fname2=fn.find_filename_with_pattern(ssp_path,\"larmip.AIS\")\n",
    "                infiles=[f'{ssp_path}/{fname1}' , f'{ssp_path}/{fname2}']\n",
    "                #\n",
    "                outfile = f\"{ssp_path}/icesheets-pb{pbox.split('_')[1]}-icesheets-{ssp}_AIS_globalsl.nc\"\n",
    "                fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "                #\n",
    "                # total\n",
    "                copy_file_with_pattern(ssp, 'wf2e', 'total.workflow')\n",
    "                #\n",
    "                fname1=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf1e\");               \n",
    "                fname2=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf2e\")\n",
    "                infiles=[f'{ssp_path}/{fname1}' , f'{ssp_path}/{fname2}'];      \n",
    "                outfile=f'{ssp_path}/total-workflow.nc'\n",
    "                fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "                #\n",
    "                #fn.delete_files_with_pattern(ssp_path, \"*AIS*\", \"icesheets-pb*\")\n",
    "                #fn.delete_files_with_pattern(ssp_path, \"*total*\", \"*-workflow*\")\n",
    "            #\n",
    "            #\n",
    "            if pbox in ['pb_1f']:\n",
    "                #\n",
    "                # AIS Pbox component.\n",
    "                fname1=fn.find_filename_with_pattern(ssp_path,\"ipccar5.icesheets_AIS\")\n",
    "                fname2=fn.find_filename_with_pattern(ssp_path,\"larmip.AIS\")\n",
    "                infiles=[f'{ssp_path}/{fname1}' , f'{ssp_path}/{fname2}']\n",
    "                #\n",
    "                outfile = f\"{ssp_path}/icesheets-pb{pbox.split('_')[1]}-icesheets-{ssp}_AIS_globalsl.nc\"\n",
    "                fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "                #\n",
    "                # total\n",
    "                copy_file_with_pattern(ssp, 'wf2f', 'total.workflow')\n",
    "                #\n",
    "                fname1=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf1f\");               \n",
    "                fname2=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf2f\")\n",
    "                infiles=[f'{ssp_path}/{fname1}' , f'{ssp_path}/{fname2}'];      \n",
    "                outfile=f'{ssp_path}/total-workflow.nc'\n",
    "                fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "                #\n",
    "                #fn.delete_files_with_pattern(ssp_path, \"*AIS*\", \"icesheets-pb*\")\n",
    "                #fn.delete_files_with_pattern(ssp_path, \"*total*\", \"*-workflow*\")\n",
    "        #\n",
    "        #\n",
    "        if pbox in ['pb_2e']:\n",
    "            copy_all_wf_files(pbox, ssp, ssp_path) \n",
    "            # Also copy\n",
    "            copy_file_with_pattern(ssp, 'wf1e', 'emulandice.AIS')\n",
    "            copy_file_with_pattern(ssp, 'wf3e', 'deconto21.AIS')\n",
    "            copy_file_with_pattern(ssp, 'wf4' , 'bamber19.icesheets_AIS') \n",
    "            copy_file_with_pattern(ssp, 'wf4' , 'bamber19.icesheets_GIS')\n",
    "            copy_file_with_pattern(ssp, 'wf1f', 'ipccar5.glaciers')\n",
    "            #\n",
    "            # AIS Pbox component\n",
    "            fname1=fn.find_filename_with_pattern(ssp_path,\"emulandice.AIS\")\n",
    "            fname2=fn.find_filename_with_pattern(ssp_path,\"larmip.AIS\")\n",
    "            fname3=fn.find_filename_with_pattern(ssp_path,\"deconto21.AIS\")\n",
    "            fname4=fn.find_filename_with_pattern(ssp_path,\"bamber19.icesheets_AIS\")\n",
    "            infiles=[f'{ssp_path}/{fname1}' , f'{ssp_path}/{fname2}', f'{ssp_path}/{fname3}' , f'{ssp_path}/{fname4}']\n",
    "            outfile = f\"{ssp_path}/icesheets-pb{pbox.split('_')[1]}-icesheets-{ssp}_AIS_globalsl.nc\"\n",
    "            fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "            #   \n",
    "            # GIS Pbox component\n",
    "            fname1=fn.find_filename_with_pattern(ssp_path,\"emulandice.GrIS\")\n",
    "            fname2=fn.find_filename_with_pattern(ssp_path,\"bamber19.icesheets_GIS\")\n",
    "            infiles=[f'{ssp_path}/{fname1}' , f'{ssp_path}/{fname2}']\n",
    "            outfile = f\"{ssp_path}/icesheets-pb{pbox.split('_')[1]}-icesheets-{ssp}_GIS_globalsl.nc\"\n",
    "            fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)   \n",
    "            #\n",
    "            # Glaciers Pbox component\n",
    "            fname1=fn.find_filename_with_pattern(ssp_path,\"emulandice.glaciers\")\n",
    "            fname2=fn.find_filename_with_pattern(ssp_path,\"ipccar5.glaciers\")\n",
    "            infiles=[f'{ssp_path}/{fname1}' , f'{ssp_path}/{fname2}']\n",
    "            outfile = f\"{ssp_path}/glaciers-pb{pbox.split('_')[1]}-glaciers-{ssp}_globalsl.nc\"\n",
    "            fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "            #\n",
    "            # total\n",
    "            copy_file_with_pattern(ssp, 'wf1e', 'total.workflow')\n",
    "            copy_file_with_pattern(ssp, 'wf3e', 'total.workflow')\n",
    "            copy_file_with_pattern(ssp, 'wf4' , 'total.workflow') \n",
    "            fname1=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf2e\");               \n",
    "            fname2=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf1e\"); \n",
    "            fname3=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf3e\"); \n",
    "            fname4=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf4\")\n",
    "            infiles=[f'{ssp_path}/{fname1}' , f'{ssp_path}/{fname2}', f'{ssp_path}/{fname3}', f'{ssp_path}/{fname4}']; \n",
    "            outfile=f'{ssp_path}/total-workflow.nc'\n",
    "            fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "            #\n",
    "            #fn.delete_files_with_pattern(ssp_path, \"*AIS*\", \"icesheets-pb*\")\n",
    "            #fn.delete_files_with_pattern(ssp_path, \"*GIS*\", \"icesheets-pb*\")\n",
    "            #fn.delete_files_with_pattern(ssp_path, \"*glaciers*\", \"glaciers-pb*\")\n",
    "            #fn.delete_files_with_pattern(ssp_path, \"*total*\", \"*-workflow*\")\n",
    "        #\n",
    "        #        \n",
    "        if pbox in ['pb_2f']:\n",
    "            copy_all_wf_files(pbox, ssp, ssp_path) \n",
    "            # Also copy\n",
    "            copy_file_with_pattern(ssp, 'wf1f', 'ipccar5.icesheets_AIS*');\n",
    "            copy_file_with_pattern(ssp, 'wf3f', 'deconto21.AIS*')\n",
    "            copy_file_with_pattern(ssp, 'wf4' , 'bamber19.icesheets_AIS*');\n",
    "            copy_file_with_pattern(ssp, 'wf4' , 'bamber19.icesheets_GIS')\n",
    "            #\n",
    "            # AIS Pbox component\n",
    "            fname1=fn.find_filename_with_pattern(ssp_path,\"ipccar5.icesheets_AIS\")\n",
    "            fname2=fn.find_filename_with_pattern(ssp_path,\"larmip.AIS\")\n",
    "            fname3=fn.find_filename_with_pattern(ssp_path,\"deconto21.AIS\")\n",
    "            fname4=fn.find_filename_with_pattern(ssp_path,\"bamber19.icesheets_AIS\")\n",
    "            infiles=[f'{ssp_path}/{fname1}' , f'{ssp_path}/{fname2}', f'{ssp_path}/{fname3}' , f'{ssp_path}/{fname4}']\n",
    "            outfile = f\"{ssp_path}/icesheets-pb{pbox.split('_')[1]}-icesheets-{ssp}_AIS_globalsl.nc\"\n",
    "            fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "            #   \n",
    "            # GIS Pbox component\n",
    "            fname1=fn.find_filename_with_pattern(ssp_path,\"GrIS1f.FittedISMIP.GrIS\")\n",
    "            fname2=fn.find_filename_with_pattern(ssp_path,\"bamber19.icesheets_GIS\")\n",
    "            infiles=[f'{ssp_path}/{fname1}' , f'{ssp_path}/{fname2}']\n",
    "            outfile = f\"{ssp_path}/icesheets-pb{pbox.split('_')[1]}-icesheets-{ssp}_GIS_globalsl.nc\"\n",
    "            fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)   \n",
    "            #\n",
    "            # total\n",
    "            copy_file_with_pattern(ssp, 'wf1f', 'total.workflow')\n",
    "            copy_file_with_pattern(ssp, 'wf3f', 'total.workflow')\n",
    "            copy_file_with_pattern(ssp, 'wf4' , 'total.workflow') \n",
    "            fname1=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf1f\");               \n",
    "            fname2=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf2f\"); \n",
    "            fname3=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf3f\"); \n",
    "            fname4=fn.find_filename_with_pattern(ssp_path,\"total.workflow.wf4\")\n",
    "            infiles=[f'{ssp_path}/{fname1}' , f'{ssp_path}/{fname2}', f'{ssp_path}/{fname3}', f'{ssp_path}/{fname4}']; \n",
    "            outfile=f'{ssp_path}/total-workflow.nc'\n",
    "            fn.generate_pbox(infiles, outfile, pyear_start=2020, pyear_end=2100, pyear_step=10)\n",
    "            #\n",
    "            #fn.delete_files_with_pattern(ssp_path, \"*AIS*\", \"icesheets-pb*\")\n",
    "            #fn.delete_files_with_pattern(ssp_path, \"*GIS*\", \"icesheets-pb*\")\n",
    "            #fn.delete_files_with_pattern(ssp_path, \"*total*\", \"*-workflow*\")            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"font-size: 32pt; color: red; font-family: 'Times New Roman'\"> \n",
    "    Generate:: <br>\n",
    "    <ol style=\"font-size: 12pt; color: green; font-family: 'Times New Roman'\">\n",
    "    <li> Confidence level files files and folders</li>\n",
    "</ol>  \n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = fn.create_directory(\"3_confidence_level_files\",,\"remove\")\n",
    "# fn.generate_confidence_files(os.getcwd()+'/2_pbox', path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
