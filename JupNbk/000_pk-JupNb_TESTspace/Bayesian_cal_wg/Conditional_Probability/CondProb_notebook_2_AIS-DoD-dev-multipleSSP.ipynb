{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 22pt; color: green; font-family: 'Times New Roman';\">\n",
    " Import Modules necessary for running this notebook \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import fun_CondProb as fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Times New Roman'; font-size: 32px; color: red;\"> List available FACTS Data:: <br> </span>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 22px; color: green;\"> :: FACTS 1.1.1 </span> \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Index                                                    File Name\n",
      "     0     coupling.ssp585.ar5AIS.ipccar5.icesheets_AIS_globalsl.nc\n",
      "     1    coupling.ssp585.ar5AIS.ipccar5.icesheets_EAIS_globalsl.nc\n",
      "     2     coupling.ssp585.ar5AIS.ipccar5.icesheets_GIS_globalsl.nc\n",
      "     3    coupling.ssp585.ar5AIS.ipccar5.icesheets_WAIS_globalsl.nc\n",
      "     4  coupling.ssp585.bamber19.bamber19.icesheets_AIS_globalsl.nc\n",
      "     5 coupling.ssp585.bamber19.bamber19.icesheets_EAIS_globalsl.nc\n",
      "     6 coupling.ssp585.bamber19.bamber19.icesheets_WAIS_globalsl.nc\n",
      "     7      coupling.ssp585.deconto21.deconto21.AIS_AIS_globalsl.nc\n",
      "     8     coupling.ssp585.deconto21.deconto21.AIS_EAIS_globalsl.nc\n",
      "     9     coupling.ssp585.deconto21.deconto21.AIS_WAIS_globalsl.nc\n",
      "    10       coupling.ssp585.emuAIS.emulandice.AIS_EAIS_globalsl.nc\n",
      "    11        coupling.ssp585.emuAIS.emulandice.AIS_PEN_globalsl.nc\n",
      "    12       coupling.ssp585.emuAIS.emulandice.AIS_WAIS_globalsl.nc\n",
      "    13            coupling.ssp585.emuAIS.emulandice.AIS_globalsl.nc\n",
      "    14           coupling.ssp585.larmip.larmip.AIS_EAIS_globalsl.nc\n",
      "    15            coupling.ssp585.larmip.larmip.AIS_PEN_globalsl.nc\n",
      "    16            coupling.ssp585.larmip.larmip.AIS_SMB_globalsl.nc\n",
      "    17           coupling.ssp585.larmip.larmip.AIS_WAIS_globalsl.nc\n",
      "    18                coupling.ssp585.larmip.larmip.AIS_globalsl.nc\n"
     ]
    }
   ],
   "source": [
    "ssp='ssp585'\n",
    "# path = f'/projects/kopp/ar2208/factsv1.1.1/coupling.{ssp}/output/'\n",
    "path = f'/Users/dota/werk/2022_09_FACTS/0000_facts-OPdata/amarel/ar2208/factsv1.1.1/coupling.{ssp}/output/'\n",
    "files=fn.list_files_with_names(path, [\"global\", \"AIS\"])\n",
    "#\n",
    "df = pd.DataFrame(files, columns=['File Name']).reset_index().rename(columns={'index': 'Index'})\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; height: 2px; background-color: none; border-style: dotted;\">\n",
    "<p style=\"font-size: 32px; color: green;\">&#10145; Choose <span style=\"color: blue;\">AIS</span> data file.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-size: 16px;\"> Use a dictionary saving method </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_year=2020; end_year=2100; unit='cm'; station=0\n",
    "\n",
    "ssps = ['ssp126','ssp119', 'ssp245','ssp370', 'ssp585']\n",
    "\n",
    "# Dictionary to store the results from each SSP scenario\n",
    "lar_ssp_results = {}\n",
    "\n",
    "# Loop over each SSP scenario\n",
    "for ssp in ssps:\n",
    "    # Construct the file path for each scenario\n",
    "    path = f'/Users/dota/werk/2022_09_FACTS/0000_facts-OPdata/amarel/ar2208/factsv1.1.1/coupling.{ssp}/output/'\n",
    "    AIS_lar_path = f'{path}/coupling.{ssp}.larmip.larmip.AIS_globalsl.nc'\n",
    "\n",
    "    # Extract the information and store it in the dictionary\n",
    "    lar_ssp_results[ssp] = {}\n",
    "    lar_ssp_results[ssp]['dat'], lar_ssp_results[ssp]['slc'], lar_ssp_results[ssp]['time'], lar_ssp_results[ssp]['lat'], lar_ssp_results[ssp]['lon'] = fn.extract_nc_info(AIS_lar_path, station, unit, start_year, end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the results from each SSP scenario\n",
    "b19_ssp_results = {}\n",
    "\n",
    "# Loop over each SSP scenario\n",
    "for ssp in ssps:\n",
    "    # Construct the file path for each scenario\n",
    "    path = f'/Users/dota/werk/2022_09_FACTS/0000_facts-OPdata/amarel/ar2208/factsv1.1.1/coupling.{ssp}/output/'\n",
    "    AIS_b19_path = f'{path}/coupling.{ssp}.bamber19.bamber19.icesheets_AIS_globalsl.nc'\n",
    "\n",
    "    # Extract the information and store it in the dictionary\n",
    "    b19_ssp_results[ssp] = {}\n",
    "    b19_ssp_results[ssp]['dat'], b19_ssp_results[ssp]['slc'], b19_ssp_results[ssp]['time'], b19_ssp_results[ssp]['lat'], b19_ssp_results[ssp]['lon'] = fn.extract_nc_info(AIS_b19_path, station, unit, start_year, end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-size: 16px;\"> optimize further::  Use a dictionary saving method </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year=2020; end_year=2100; unit='cm'; station=0\n",
    "ssps = ['ssp126','ssp119', 'ssp245','ssp370', 'ssp585']\n",
    "\n",
    "# Base path of data folder (all ssp).\n",
    "base_path = '/Users/dota/werk/2022_09_FACTS/0000_facts-OPdata/amarel/ar2208/factsv1.1.1'\n",
    "\n",
    "lar_ssp_results = {}\n",
    "\n",
    "# Loop over each SSP scenario\n",
    "for ssp in ssps:\n",
    "    file_path = f'{base_path}/coupling.{ssp}/output/coupling.{ssp}.larmip.larmip.AIS_globalsl.nc'\n",
    "    dat, slc, time, lat, lon = fn.extract_nc_info(file_path, station, unit, start_year, end_year)\n",
    "    lar_ssp_results[ssp] = {'dat': dat, 'slc': slc, 'time': time, 'lat': lat, 'lon': lon, 'path': file_path}\n",
    "del dat, slc, time, lat, lon, ssp, file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-size: 16px;\"> optimize further::  <span style=\"color: black;\">extract multiple files </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year=2020; end_year=2100; unit='cm'; station=0\n",
    "ssps = ['ssp126','ssp119', 'ssp245','ssp370', 'ssp585']\n",
    "\n",
    "# Base path of data folder (all ssp).\n",
    "base_path = '/Users/dota/werk/2022_09_FACTS/0000_facts-OPdata/amarel/ar2208/factsv1.1.1'\n",
    "\n",
    "# Dictionary of filenames\n",
    "file_names = {\n",
    "    'lar': 'larmip.larmip.AIS_globalsl.nc',\n",
    "    'b19': 'bamber19.bamber19.icesheets_AIS_globalsl.nc'\n",
    "}\n",
    "\n",
    "# Dictionary to store the results\n",
    "ssp_results = {key: {} for key in file_names}\n",
    "\n",
    "# Loop over each SSP scenario\n",
    "for ssp in ssps:\n",
    "    for key, filename in file_names.items():\n",
    "        file_path = f'{base_path}/coupling.{ssp}/output/coupling.{ssp}.{filename}'\n",
    "        dat, slc, time, lat, lon = fn.extract_nc_info(file_path, station, unit, start_year, end_year)\n",
    "        ssp_results[key][ssp] = {'dat': dat, 'slc': slc, 'time': time, 'lat': lat, 'lon': lon, 'path': file_path}\n",
    "del dat, slc, time, lat, lon, ssp, file_path, key, file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; height: 2px; background-color: none; border-style: dotted;\">\n",
    "<span style=\"font-family: 'Times New Roman'; font-size: 22pt; color: green;\">\n",
    "    Select Plot data.\n",
    "</span>\n",
    "<br>\n",
    "<span style=\"font-family: 'Times New Roman'; font-size: 16pt; color: blue;\">\n",
    "    :: Extract all samples from a particulay year \n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axis_data(dum_slc, dum_time, *specific_year):\n",
    "    return [dum_slc[:, dum_time == t].squeeze() for t in specific_year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1=2030; T2=2050; T3=2070; T4=2090; T5=2100\n",
    "var='lar'\n",
    "\n",
    "# Initialize lists to store stacked data for each time point\n",
    "exec(f'{var}_ALLssp_{T1} = []')\n",
    "exec(f'{var}_ALLssp_{T2} = []')\n",
    "exec(f'{var}_ALLssp_{T3} = []')\n",
    "exec(f'{var}_ALLssp_{T4} = []')\n",
    "exec(f'{var}_ALLssp_{T5} = []')\n",
    "\n",
    "# Loop over each SSP scenario\n",
    "for ssp in ssps:\n",
    "    # Extracting variables for the current SSP scenario\n",
    "    exec(f\"{var}_ssp_slc = {var}_ssp_results['{ssp}']['slc']\")\n",
    "    exec(f\"{var}_ssp_time = {var}_ssp_results['{ssp}']['time']\")\n",
    "\n",
    "    # Call get_axis_data with these variables and the time points\n",
    "    exec(f\"{var}_ssp_{T1}, {var}_ssp_{T2}, {var}_ssp_{T3}, {var}_ssp_{T4}, {var}_ssp_{T5} = get_axis_data({var}_ssp_slc, {var}_ssp_time, {T1}, {T2}, {T3}, {T4}, {T5})\")\n",
    "\n",
    "    # Append the data to the respective lists\n",
    "    exec(f'{var}_ALLssp_{T1}.append({var}_ssp_{T1})')\n",
    "    exec(f'{var}_ALLssp_{T2}.append({var}_ssp_{T2})')\n",
    "    exec(f'{var}_ALLssp_{T3}.append({var}_ssp_{T3})')\n",
    "    exec(f'{var}_ALLssp_{T4}.append({var}_ssp_{T4})')\n",
    "    exec(f'{var}_ALLssp_{T5}.append({var}_ssp_{T5})')\n",
    "\n",
    "# stack\n",
    "exec(f'{var}_ALLssp_{T1}_array = np.hstack({var}_ALLssp_{T1})')\n",
    "exec(f'{var}_ALLssp_{T2}_array = np.hstack({var}_ALLssp_{T2})')\n",
    "exec(f'{var}_ALLssp_{T3}_array = np.hstack({var}_ALLssp_{T3})')\n",
    "exec(f'{var}_ALLssp_{T4}_array = np.hstack({var}_ALLssp_{T4})')\n",
    "exec(f'{var}_ALLssp_{T5}_array = np.hstack({var}_ALLssp_{T5})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1=2030; T2=2050; T3=2070; T4=2090; T5=2100\n",
    "var='b19'\n",
    "\n",
    "# Initialize lists to store stacked data for each time point\n",
    "exec(f'{var}_ALLssp_{T1} = []')\n",
    "exec(f'{var}_ALLssp_{T2} = []')\n",
    "exec(f'{var}_ALLssp_{T3} = []')\n",
    "exec(f'{var}_ALLssp_{T4} = []')\n",
    "exec(f'{var}_ALLssp_{T5} = []')\n",
    "\n",
    "# Loop over each SSP scenario\n",
    "for ssp in ssps:\n",
    "    # Extracting variables for the current SSP scenario\n",
    "    exec(f\"{var}_ssp_slc = {var}_ssp_results['{ssp}']['slc']\")\n",
    "    exec(f\"{var}_ssp_time = {var}_ssp_results['{ssp}']['time']\")\n",
    "\n",
    "    # Call get_axis_data with these variables and the time points\n",
    "    exec(f\"{var}_ssp_{T1}, {var}_ssp_{T2}, {var}_ssp_{T3}, {var}_ssp_{T4}, {var}_ssp_{T5} = get_axis_data({var}_ssp_slc, {var}_ssp_time, {T1}, {T2}, {T3}, {T4}, {T5})\")\n",
    "\n",
    "    # Append the data to the respective lists\n",
    "    exec(f'{var}_ALLssp_{T1}.append({var}_ssp_{T1})')\n",
    "    exec(f'{var}_ALLssp_{T2}.append({var}_ssp_{T2})')\n",
    "    exec(f'{var}_ALLssp_{T3}.append({var}_ssp_{T3})')\n",
    "    exec(f'{var}_ALLssp_{T4}.append({var}_ssp_{T4})')\n",
    "    exec(f'{var}_ALLssp_{T5}.append({var}_ssp_{T5})')\n",
    "\n",
    "# stack\n",
    "exec(f'{var}_ALLssp_{T1}_array = np.hstack({var}_ALLssp_{T1})')\n",
    "exec(f'{var}_ALLssp_{T2}_array = np.hstack({var}_ALLssp_{T2})')\n",
    "exec(f'{var}_ALLssp_{T3}_array = np.hstack({var}_ALLssp_{T3})')\n",
    "exec(f'{var}_ALLssp_{T4}_array = np.hstack({var}_ALLssp_{T4})')\n",
    "exec(f'{var}_ALLssp_{T5}_array = np.hstack({var}_ALLssp_{T5})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; height: 2px; background-color: none; border-style: dotted;\">\n",
    "<span style=\"font-family: 'Times New Roman'; font-size: 22pt; color: green;\">\n",
    "    PLOT PDF's :: </span> \n",
    "<span style=\"color: red;\"> LOG scale </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Times New Roman'; font-size: 16pt; color: black;\"> Larmip AIS </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "axis_limits = {\n",
    "    0: {'xlim': (0, 6, 1), 'ylim': (0, 60, 10)},\n",
    "    1: {'xlim': (0, 15, 2), 'ylim': (0, 60, 10)},\n",
    "    2: {'xlim': (0, 30, 5), 'ylim': (0, 60, 10)},\n",
    "    3: {'xlim': (0, 50, 10), 'ylim': (0, 60, 10)}\n",
    "}\n",
    "fn.plot_1file('LARMIP',lar_ALLssp_2030_array,lar_ALLssp_2050_array, lar_ALLssp_2070_array, lar_ALLssp_2090_array, lar_ALLssp_2100_array, 2030,2050,2070,2090,2100,\n",
    "             None, None, None, None, 100, 1e-4,  'Reds','LOG', 5,\n",
    "               'AIS',10, axis_limits, None,0.04,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Times New Roman'; font-size: 16pt; color: black;\"> Bamber 19 AIS </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_limits = {\n",
    "    0: {'xlim': (0, 6, 2), 'ylim': (0, 60, 10)},\n",
    "    1: {'xlim': (0, 15, 2), 'ylim': (0, 60, 10)},\n",
    "    2: {'xlim': (0, 30, 5), 'ylim': (0, 60, 10)},\n",
    "    3: {'xlim': (0, 50, 10), 'ylim': (0, 60, 10)}\n",
    "}\n",
    "fn.plot_1file('Bamber 19',b19_ALLssp_2030_array,b19_ALLssp_2050_array, b19_ALLssp_2070_array, b19_ALLssp_2090_array, b19_ALLssp_2100_array, 2030,2050,2070,2090,2100,\n",
    "             None, None, None, None, 100, 1e-4,  'Blues', 'LOG', 5,\n",
    "               'AIS',10, axis_limits, None,0.002,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; height: 4px; background-color: yellow; border-style: dotted;\">\n",
    "<span style=\"font-family: 'Times New Roman'; font-size: 16pt; color: black;\"> Plot stacked Combined </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_limits = {\n",
    "    0: {'xlim': (0, 6, 1), 'ylim': (0, 60, 10)},\n",
    "    1: {'xlim': (0, 15, 2), 'ylim': (0, 60, 10)},\n",
    "    2: {'xlim': (0, 30, 5), 'ylim': (0, 60, 10)},\n",
    "    3: {'xlim': (0, 50, 10), 'ylim': (0, 60, 10)}\n",
    "}\n",
    "fn.plot_1file('LARMIP',lar_ALLssp_2030_array,lar_ALLssp_2050_array, lar_ALLssp_2070_array, lar_ALLssp_2090_array, lar_ALLssp_2100_array, 2030,2050,2070,2090,2100,\n",
    "             None, None, None, None, 100, 1e-4,  'Reds','LOG', 5,\n",
    "               'AIS',10, axis_limits, None,0.04,1)\n",
    "\n",
    "fn.plot_1file('Bamber 19',b19_ALLssp_2030_array,b19_ALLssp_2050_array, b19_ALLssp_2070_array, b19_ALLssp_2090_array, b19_ALLssp_2100_array, 2030,2050,2070,2090,2100,\n",
    "             None, None, None, None, 100, 1e-4,  'Blues', 'LOG', 5,\n",
    "               'AIS',10, axis_limits, None,0.002)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; height: 2px; background-color: none; border-style: dotted;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plot_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
